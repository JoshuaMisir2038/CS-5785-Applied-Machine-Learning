{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training data points: 7613\n",
      "Number of test data points: 3263\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import re\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "########## 1. Download the Data ##########\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# 1A How many training and test data points are there?\n",
    "\n",
    "print(f\"Number of training data points: {train.shape[0]}\")\n",
    "print(f\"Number of test data points: {test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the percentage of real disasters in the training set is: 42.97 % \n",
      "the percentage of tweets that are not actual disasters in the training set is: 57.03%\n"
     ]
    }
   ],
   "source": [
    "# 1A what percentage of the training tweets are real disasters and are not?\n",
    "\n",
    "percent_real = (train[\"target\"].sum()/ train.shape[0]) * 100\n",
    "print(f\"the percentage of real disasters in the training set is: {round(percent_real, 2)} % \")\n",
    "print(f\"the percentage of tweets that are not actual disasters in the training set is: {round(100 - percent_real,2)}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1b Split the training data set into a training set and development set 70/30\n",
    "\n",
    "training_split = train.sample(frac = .70)\n",
    "development_split = train.drop(training_split.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1C - remove all Twitter tags\n",
    "\n",
    "\n",
    "training_split['text'] = training_split['text'].replace(r'@[A-Za-z0-9]+', '', regex=True)\n",
    "development_split['text'] = development_split['text'].replace(r'@[A-Za-z0-9]+', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1C Preprocess the data\n",
    "\n",
    "# 1C - overting all letters to lowercase\n",
    "training_split['text'] = training_split.text.apply(lambda x: x.lower())\n",
    "development_split['text'] = development_split.text.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1C -  remove all special characters and punctuation\n",
    "\n",
    "training_split['text'] = training_split['text'].replace(r'[^\\w\\s]|_', '', regex=True)\n",
    "development_split['text'] = development_split['text'].replace(r'[^\\w\\s]|_', '', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1C - remove all URLS (e.g. https and www.)\n",
    "\n",
    "training_split['text'] = training_split['text'].replace(r'http\\S+|www.\\.\\S+', '', regex=True)\n",
    "development_split['text'] = development_split['text'].replace(r'http\\S+|www.\\.\\S+', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1C - strip all the stop words (e.g. the, and, or)\n",
    "\n",
    "\n",
    "training_split['text'] = training_split['text'].replace(r'(\\s*\\b(?:a|an|and|are|as|at|be|but|by|for|if|in|into|is|it|no|not|of|on|or|such|that|the|their|then|there|these|they|this|to|was|will|with|my|oh|i|were|werent|was|wasnt|do|does))\\b', '', regex=True)\n",
    "development_split['text'] = development_split['text'].replace(r'(\\s*\\b(?:a|an|and|are|as|at|be|but|by|for|if|in|into|is|it|no|not|of|on|or|such|that|the|their|then|there|these|they|this|to|was|will|with|my|oh|i|were|werent|was|wasnt|do|does))\\b', '', regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/joshuamisir/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/joshuamisir/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/joshuamisir/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# 1C - Lemmatize all the words\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import tokenize, stem, corpus\n",
    "\n",
    "\n",
    "lemmatizer = stem.WordNetLemmatizer()\n",
    "\n",
    "# Get the POS Tag for lemmatization (reference: https://medium.com/@yashj302/lemmatization-f134b3089429 )\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].lower()\n",
    "    tag_dict = {'j': corpus.wordnet.ADJ,\n",
    "                'n': corpus.wordnet.NOUN,\n",
    "                'v': corpus.wordnet.VERB,\n",
    "                'r': corpus.wordnet.ADV}\n",
    "    return tag_dict.get(tag, corpus.wordnet.NOUN)\n",
    "\n",
    "# apply lemmatizer on the text column\n",
    "training_split['text'] = training_split.text.apply(lambda x: ' '.join([lemmatizer.lemmatize(y, get_wordnet_pos(y)) for y in tokenize.word_tokenize(x)]))\n",
    "development_split['text'] = development_split.text.apply(lambda x: ' '.join([lemmatizer.lemmatize(y, get_wordnet_pos(y)) for y in tokenize.word_tokenize(x)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1d) Bag of words model & determining optimal M\n",
    "\n",
    "f1_trainlist = []\n",
    "f1_devlist = []\n",
    "\n",
    "# threshold for bag of words \n",
    "for M in range(12, 30):\n",
    "\n",
    "# Perform CountVectorizer on text. This creates three numbers:\n",
    "# 1) list of rows which represent tweets\n",
    "# 2) a feature index which represents a distinct word within that tweet \n",
    "# 3) a count which represents how many times that word has been used\n",
    "    \n",
    "    count_vect = CountVectorizer(binary=True, min_df=M)\n",
    "    X_train = count_vect.fit_transform(training_split['text'])\n",
    "\n",
    "    # need to make dev set transformed to fit X_train size\n",
    "    X_dev = count_vect.transform(development_split['text'])\n",
    "\n",
    "    # create logistic model\n",
    "    logreg = LogisticRegression(multi_class='auto', penalty='none', max_iter=3000)\n",
    "    logreg.fit(X_train, training_split['target'].values)\n",
    "\n",
    "    # calculate F1 score\n",
    "    f1_train = f1_score(training_split['target'].values, logreg.predict(X_train))\n",
    "    f1_dev = f1_score(development_split['target'].values, logreg.predict(X_dev))\n",
    "\n",
    "    f1_trainlist.append(f1_train)\n",
    "    f1_devlist.append(f1_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot to determine optimal M\n",
    "plt.plot(range(12, 30), f1_trainlist, label=\"Training Set\")\n",
    "plt.plot(range(12, 30), f1_devlist, label=\"Dev Set\")\n",
    "plt.xlabel(\"M Threshold\")\n",
    "plt.ylabel(\"F1-Score\")\n",
    "leg = plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "\n",
    "# F1-Dev Score is maxed at ~M = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 13\n",
    "\n",
    "# Perform CountVectorizer on text\n",
    "count_vect = CountVectorizer(binary=True, min_df=M)\n",
    "X_train = count_vect.fit_transform(training_split['text'])\n",
    "\n",
    "# need to make dev set transformed to fit X_train size\n",
    "X_dev = count_vect.transform(development_split['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set with no regularization terms F1-Score is: 0.8389888408107492\n",
      "Development set with no regularization terms F1-Score is: 0.7101827676240209\n"
     ]
    }
   ],
   "source": [
    "# 1e) i - LogisticRegression with no regularization. Penalty = none\n",
    "\n",
    "# The F1 score on the training set is higher than the F1 score on the development set which contains unseen data\n",
    "# This is an example of  overfitting. \n",
    "# Our model is too strongly fitted to the training data when there is no regularization in the Logistic Regression\n",
    "# This is due to the fact that there is no regularization factor in this logistic regression.\n",
    "# The lack of regularization makes this model too sensative to the \"noise\" (data points that dont truly represent the data) \n",
    "# in the data set\n",
    "\n",
    "logreg = LogisticRegression(multi_class='ovr', penalty='none', max_iter=2500)\n",
    "logreg.fit(X_train, training_split['target'].values)\n",
    "\n",
    "# calculate F1 score\n",
    "f1_train = f1_score(training_split['target'].values, logreg.predict(X_train))\n",
    "f1_dev = f1_score(development_split['target'].values, logreg.predict(X_dev))\n",
    "\n",
    "\n",
    "# print F1 values out\n",
    "#print(f\"Training set with no regularization terms F1-Score is: {round(f1_train,3)}\")\n",
    "#print(f\"Development set with no regularization terms F1-Score is: {round(f1_dev,3)}\")\n",
    "\n",
    "print(f\"Training set with no regularization terms F1-Score is: {f1_train}\")\n",
    "print(f\"Development set with no regularization terms F1-Score is: {f1_dev}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set with L2 regularization F1-Score is 0.8085405912717033\n",
      "Development set with L2 regularization F1-Score is 0.7231021299836154\n"
     ]
    }
   ],
   "source": [
    "# 1e) ii - LogisticRegression with L1 regularization. \n",
    "\n",
    "\n",
    "logreg1 = LogisticRegression(penalty='l1', max_iter=2500, solver='liblinear')\n",
    "logreg1.fit(X_train, training_split['target'].values)\n",
    "\n",
    "# calculate F1 score\n",
    "f1_train_reg1 = f1_score(training_split['target'].values, logreg1.predict(X_train))\n",
    "f1_dev_reg1 = f1_score(development_split['target'].values, logreg1.predict(X_dev))\n",
    "\n",
    "\n",
    "#print F1 values out\n",
    "print(f\"Training set with L2 regularization F1-Score is {f1_train_reg1}\")\n",
    "print(f\"Development set with L2 regularization F1-Score is {f1_dev_reg1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set with L2 regularization F1-Score is 0.8225391629646949\n",
      "Development set with L2 regularization F1-Score is 0.7241192411924119\n"
     ]
    }
   ],
   "source": [
    "# 1e) iii - LogisticRegression with L2 regularization. \n",
    "\n",
    "\n",
    "logreg2 = LogisticRegression(penalty='l2', max_iter=2500)\n",
    "logreg2.fit(X_train, training_split['target'].values)\n",
    "\n",
    "# calculate F1 score\n",
    "f1_train_reg2 = f1_score(training_split['target'].values, logreg2.predict(X_train))\n",
    "f1_dev_reg2 = f1_score(development_split['target'].values, logreg2.predict(X_dev))\n",
    "\n",
    "\n",
    "#print F1 values out\n",
    "print(f\"Training set with L2 regularization F1-Score is {f1_train_reg2}\")\n",
    "print(f\"Development set with L2 regularization F1-Score is {f1_dev_reg2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1e) iv - Which one of the three classifiers performed the best on your training and development set?\n",
    "\n",
    "# The best performing model on both the training and development set was the \n",
    "# Logistic Regression with L2 regularization. \n",
    "# The superior outcomes for this logistic regression can best be explained by the fact that L2\n",
    "# squares the magnitude of the coeffecicients whereas the L1 regularization takes the absolute value\n",
    "# of the coeffecients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bioterror', 'bomber', 'bombing', 'bridge', 'bus', 'casualty', 'catastrophic', 'coach', 'crew', 'cyclone', 'derailment', 'drought', 'earthquake', 'evacuation', 'explosion', 'flood', 'found', 'hailstorm', 'helicopter', 'hiroshima', 'japan', 'legionnaire', 'libya', 'massacre', 'mh370', 'migrant', 'murder', 'muslim', 'myanmar', 'near', 'outbreak', 'refugee', 'rioting', 'severe', 'spill', 'storm', 'survivor', 'swallow', 'terrorism', 'terrorist', 'tornado', 'train', 'typhoon', 'victim', 'village', 'volcano', 'wildfire']\n"
     ]
    }
   ],
   "source": [
    "# 1e) v.  Inspect weight vector of classifier with L1 regularization\n",
    "\n",
    "# retrieve index from coefficiets that are greater than a value\n",
    "impt_index = [i for i,v in enumerate(logreg1.coef_.tolist()[0]) if v > 1.5]\n",
    "\n",
    "# map the index to the actual words\n",
    "impt_words = [count_vect.get_feature_names()[i] for i in impt_index]\n",
    "\n",
    "# The most important words in determining if the Tweet was a real disaster\n",
    "print(impt_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The most important words in determining if the Tweet was a real\n",
    "# disaster or not are listed below\n",
    "\n",
    "# '40', 'bioterror', 'bomber', 'bombing', 'bus', 'california', 'case'\n",
    "#  casualty', 'crew', 'crisis', 'cyclone', 'debris', 'derailment'\n",
    "# 'earthquake', 'explosion', 'fire', 'hiroshima', 'hurricane', 'israeli', \n",
    "# japan', 'massacre', 'mh370', 'migrant', 'murder', 'murderer', 'muslim',\n",
    "# 'outbreak', 'refugee', 'severe', 'sinkhole', 'south', 'spill', 'storm',\n",
    "# 'suspect', 'swallow', 'terrorist', 'train', 'typhoon', 'village'\n",
    "# 'volcano', 'wildfire'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "850"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57252768 0.42747232]\n"
     ]
    }
   ],
   "source": [
    "#1f) Bernoulli Naive Bayes\n",
    "\n",
    "# laplace smoothing parameter\n",
    "alpha = .01\n",
    "\n",
    "# create array of target values\n",
    "y_train = training_split['target'].values\n",
    "\n",
    "# convert Xtrain to array for manipulation\n",
    "X_train = X_train.toarray()\n",
    "n = X_train.shape[0]    # size of the data set\n",
    "d = X_train.shape[1]    # number of features in the data set\n",
    "K = 2                   #number of classes (Real/not real disasters)\n",
    "\n",
    "# initialize shapes of parameters\n",
    "\n",
    "#An array with two rows (classes, K) and 798 cols (features, d)\n",
    "psis = np.zeros([K,d]) \n",
    "\n",
    "# An array with K (2) number of rows\n",
    "phis = np.zeros([K])\n",
    "\n",
    "\n",
    "# calculate the parameters, and apply alpha\n",
    "for k in range(K):\n",
    "    X_k = X_train[y_train == k]\n",
    "    psis[k] = (np.sum(X_k, axis=0) + alpha)/(X_k.shape[0] + 2*alpha)\n",
    "    phis[k] = X_k.shape[0] / float(n)\n",
    "    \n",
    "print(phis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.811033965096641"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nb_predictions(x, psis, phis):\n",
    "    \"\"\"This returns class assignments and scores under the NB model.\n",
    "    \n",
    "    We compute \\arg\\max_y p(y|x) as \\arg\\max_y p(x|y)p(y)\n",
    "    \"\"\"\n",
    "    # adjust shapes\n",
    "    n, d = x.shape\n",
    "    x = np.reshape(x, (1, n, d))\n",
    "    psis = np.reshape(psis, (K, 1, d))\n",
    "    \n",
    "    # clip probabilities to avoid log(0)\n",
    "    psis = psis.clip(1e-14, 1-1e-14)\n",
    "    \n",
    "    # compute log-probabilities\n",
    "    logpy = np.log(phis).reshape([K,1])\n",
    "    logpxy = x * np.log(psis) + (1-x) * np.log(1-psis)\n",
    "    logpyx = logpxy.sum(axis=2) + logpy\n",
    "\n",
    "    return logpyx.argmax(axis=0).flatten(), logpyx.reshape([K,n])\n",
    "\n",
    "idx_train, logpyx_train = nb_predictions(X_train, psis, phis)\n",
    "\n",
    "\n",
    "(idx_train==y_train).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7876532399299475"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# calculate the predictions for dev set\n",
    "\n",
    "y_dev = development_split['target'].values\n",
    "\n",
    "# convert Xtrain to array for manipulation\n",
    "X_dev = X_dev.toarray()\n",
    "\n",
    "idx_dev, logpyx_train = nb_predictions(X_dev, psis, phis)\n",
    "\n",
    "# calculate the accurary\n",
    "(idx_dev==y_dev).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which model performed the best in predicting whether a tweet is of a real disaster or\n",
    "# not? Include your performance metric in your response. \n",
    "# Comment on the pros and cons of using generative vs discriminative models. \n",
    "# • Think about the assumptions that Naive Bayes makes. \n",
    "# How are the assumptions different from logistic regressions? Discuss whether it’s valid and efficient to use Bernoulli\n",
    "# Naive Bayes classifier for natural language texts.\n",
    "\n",
    "\n",
    "\n",
    "# 1g) The Naive Bayes model produced a better result with an accuracy rate of 80% vs. Logistic regression, which had \n",
    "# a F1-score of 72%. \n",
    "# However, NB method assumes that all the words are not correlated, which isn't true. This results in the probabilities\n",
    "# being overconfidenti n its predictions. It's valid to use Bernoulli NB classifier if the feature space is small, as it'll\n",
    "# reduce the number of instances of dependent features. Otherwise, if the feature space is large, Logistic regression is better\n",
    "\n",
    "# This can be measuered in practice. For example if you have a classification problem where you are attempting to\n",
    "# classify what city a news article is being published for, either Boston or New York. Lets assume Boston \n",
    "# and New York are refenced equally throughout the text in their respective classes. \"New York\" will contribute\n",
    "# twice the weight as one instance of \"Boston\". The summed contribution of the classification weights may be larger\n",
    "# for one class than another which will cause the NB model to favor one class over the other. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# One issue with Naive Bayes is that if there is unequal representativeness of class representations in the training data \n",
    "# within a binary classification problem, there will be a bias toward that over-represented class. This will degrade accuracy \n",
    "\n",
    "# Another assumption is that Naive Bayes assumes that words are idependent and identically distributed which \n",
    "# is a faulty assumption and is not the case in practice. \n",
    "# Certain pairs of words within sentences have a high likelihood of being seen together\n",
    "# which reduces the strength of the identical, independent distrubtion Naive Bayes makes. \n",
    "\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rebuild dataset and re-train on NB with 2-grams\n",
    "\n",
    "h_train = pd.read_csv('train.csv')\n",
    "h_test = pd.read_csv('test.csv')\n",
    "\n",
    "# Pre-processing the data\n",
    "\n",
    "# remove all lowercase from the tweet\n",
    "h_train['text'] = h_train.text.apply(lambda x: x.lower())\n",
    "h_test['text'] = h_test.text.apply(lambda x: x.lower())\n",
    "\n",
    "# remove all Twitter tags\n",
    "h_train['text'] = h_train['text'].replace(r'@[A-Za-z0-9]+', '', regex=True)\n",
    "h_test['text'] = h_test['text'].replace(r'@[A-Za-z0-9]+', '', regex=True)\n",
    "\n",
    "# remove all special characters, including punctuation\n",
    "h_train['text'] = h_train['text'].replace(r'[^\\w\\s]|_', '', regex=True)\n",
    "h_test['text'] = h_test['text'].replace(r'[^\\w\\s]|_', '', regex=True)\n",
    "\n",
    "# remove all URLs\n",
    "h_train['text'] = h_train['text'].replace(r'http\\S+|www.\\.\\S+', '', regex=True)\n",
    "h_test['text'] = h_test['text'].replace(r'http\\S+|www.\\.\\S+', '', regex=True)\n",
    "\n",
    "# strip all the stop words (e.g. the, and, or)\n",
    "h_train['text'] = h_train['text'].replace(r'(\\s*\\b(?:a|an|and|are|as|at|be|but|by|for|if|in|into|is|it|no|not|of|on|or|such|that|the|their|then|there|these|they|this|to|was|will|with|my|oh|i|were|werent|was|wasnt|do|does))\\b', '', regex=True)\n",
    "h_test['text'] = h_test['text'].replace(r'(\\s*\\b(?:a|an|and|are|as|at|be|but|by|for|if|in|into|is|it|no|not|of|on|or|such|that|the|their|then|there|these|they|this|to|was|will|with|my|oh|i|were|werent|was|wasnt|do|does))\\b', '', regex=True)\n",
    "\n",
    "# lemmatize the words\n",
    "h_train['text'] = h_train.text.apply(lambda x: ' '.join([lemmatizer.lemmatize(y, get_wordnet_pos(y)) for y in tokenize.word_tokenize(x)]))\n",
    "h_test['text'] = h_test.text.apply(lambda x: ' '.join([lemmatizer.lemmatize(y, get_wordnet_pos(y)) for y in tokenize.word_tokenize(x)]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8518323919611192"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1h) countvector with n-grams = 1,2\n",
    "\n",
    "count_vect = CountVectorizer(binary=True,ngram_range=(1,2), min_df=4)\n",
    "X_train = count_vect.fit_transform(h_train['text'])\n",
    "X_test = count_vect.transform(h_test['text'])\n",
    "\n",
    "# NB on the training data\n",
    "\n",
    "# create array of target values\n",
    "Y_train = h_train['target'].values\n",
    "\n",
    "# convert Xtrain to array for manipulation\n",
    "X_train = X_train.toarray()\n",
    "n = X_train.shape[0]  # size of the data set (number of tweets)\n",
    "d = X_train.shape[1]  # number of features in the data set\n",
    "K = 2                 # number of classes we are classification classes\n",
    "\n",
    "# initialize shapes of parameters\n",
    "psis = np.zeros([K,d])\n",
    "phis = np.zeros([K])\n",
    "\n",
    "# calculate the parameters, and apply alpha\n",
    "for k in range(K):\n",
    "    X_k = X_train[Y_train == k]\n",
    "    psis[k] = (np.sum(X_k, axis=0) + alpha)/(X_k.shape[0] + 2*alpha)\n",
    "    phis[k] = X_k.shape[0] / float(n)\n",
    "\n",
    "idx_train, logpyx_train = nb_predictions(X_train, psis, phis)\n",
    "\n",
    "# calculate the accurary\n",
    "(idx_train==Y_train).mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Xtrain to array for manipulation\n",
    "X_test = X_test.toarray()\n",
    "\n",
    "idx_test, logpyx_test= nb_predictions(X_test, psis, phis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create submission\n",
    "h_test[\"target\"] = idx_test\n",
    "submission = h_test[[\"id\",\"target\"]]\n",
    "submission.to_csv('submission_disastertweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
